{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f52536b-6b96-4c55-a3e3-0097169ec285",
   "metadata": {},
   "source": [
    "# Link de tutorial:\n",
    "https://youtu.be/qQELiV1_GHA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d5dee4-d2aa-401b-ab58-d8bccb922daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178845b-b5fb-41fc-9279-6c3bbc1da57b",
   "metadata": {},
   "source": [
    "# Importar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1c8087-ecfe-4589-9d2a-ece0853d30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b397d602-d836-4b78-97bc-a90526feb244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8305/3774853967.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float)\n",
      "/tmp/ipykernel_8305/3774853967.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_test = x_test_num.copy().reshape(10000, -1).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float32)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584098d-5091-4618-ba8e-b1fc2af28397",
   "metadata": {},
   "source": [
    "# Normalizaf imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3262938e-ba48-4658-9587-b126857ee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aac4b45b-897d-4340-9830-23756fb323c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.1638146e-07, 0.99999934)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)\n",
    "\n",
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3506dff6-97c8-4bb5-bba9-d899d599e1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3920bfd-eb26-48a9-9b38-d47627d23b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600b02c-9c36-448b-92f1-3375c22022fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mostrar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97aab8ea-158e-4857-9e23-5ea54afde8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1146c1e6-4bdc-4697-93b2-37163dfe2ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx][0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad50f8-9412-4a1c-8082-3cda411198e3",
   "metadata": {},
   "source": [
    "# Crear minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9739d963-46d2-43bb-820a-bb6789250614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(x, y, mb_size, shuffle=True):\n",
    "    '''\n",
    "    x  # muestras, 784\n",
    "    y # muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238bff9-c9dd-4570-8c02-d479ff84fb7e",
   "metadata": {},
   "source": [
    "# Convertir Numpy array a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e25f17ca-62a9-48f7-93ee-da657d2a96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.copy())\n",
    "y_train_tensor = torch.tensor(y_train.copy())\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val.copy())\n",
    "y_val_tensor = torch.tensor(y_val.copy())\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test.copy())\n",
    "y_test_tensor = torch.tensor(y_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f41ce621-98bd-461d-a969-77406350a5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos usando: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Estamos usando: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cec140-cc28-404c-af07-e858dec95688",
   "metadata": {},
   "source": [
    "# Compute accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "b4bb9e7f-2632-435d-b37e-7524f2087a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y, mb_size):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(xi) # (mb_size, 10)\n",
    "            pred = scores.argmax(dim=1) # Return de max value and index, this vector return of shape (mb_size).\n",
    "            num_correct += (pred==yi.squeeze()).sum() # yi have dimention of (batch_size, 1) so squeeze change dimention to  (mb_size).\n",
    "            num_total += pred.size(0)\n",
    "        \n",
    "        return float(num_correct)/num_total\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "efbac352-81a7-4f22-86e8-1b50ca6f171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ebf86-d0ad-4f59-b460-d38ad7ae097d",
   "metadata": {},
   "source": [
    "# Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "a530760e-829c-4a8a-860f-14eeab55885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, mb_size, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(xi)\n",
    "            \n",
    "       \n",
    "            # Funcion cost\n",
    "            cost = F.cross_entropy(\n",
    "                input=scores,\n",
    "                target=yi.squeeze(),\n",
    "                \n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f'Epoch: {epoch+1}, costo: {cost.item()}, accuracy {accuracy(model, x_val_tensor, y_val_tensor, mb_size)}')\n",
    "        \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f3ee6-b65b-47db-9799-16476e515f3d",
   "metadata": {},
   "source": [
    "# Modelo usando Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "8e7b93ad-0b84-49bb-8b11-664412604514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar model\n",
    "hidden1 = 200\n",
    "hidden = 200\n",
    "out_features = 10\n",
    "lr = 1e-2\n",
    "epochs = 20\n",
    "mb_size = 32\n",
    "model1 = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=200, out_features=out_features)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "819027e8-f927-41fc-a473-61fc27fd163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "3c67e03b-be3d-4338-956a-d460ed1351ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, costo: 0.23754945397377014, accuracy 0.9236\n",
      "Epoch: 2, costo: 0.10200522094964981, accuracy 0.9416\n",
      "Epoch: 3, costo: 0.3701179325580597, accuracy 0.9527\n",
      "Epoch: 4, costo: 0.1986532360315323, accuracy 0.9582\n",
      "Epoch: 5, costo: 0.2478952258825302, accuracy 0.962\n",
      "Epoch: 6, costo: 0.07357707619667053, accuracy 0.9674\n",
      "Epoch: 7, costo: 0.06208086386322975, accuracy 0.9692\n",
      "Epoch: 8, costo: 0.09509190171957016, accuracy 0.9703\n",
      "Epoch: 9, costo: 0.1874171942472458, accuracy 0.9712\n",
      "Epoch: 10, costo: 0.1297401487827301, accuracy 0.9726\n",
      "Epoch: 11, costo: 0.6440955996513367, accuracy 0.9726\n",
      "Epoch: 12, costo: 0.004894021432846785, accuracy 0.974\n",
      "Epoch: 13, costo: 0.027778729796409607, accuracy 0.975\n",
      "Epoch: 14, costo: 0.033005859702825546, accuracy 0.9743\n",
      "Epoch: 15, costo: 0.07156600058078766, accuracy 0.9749\n",
      "Epoch: 16, costo: 0.010151092894375324, accuracy 0.9757\n",
      "Epoch: 17, costo: 0.13079728186130524, accuracy 0.9752\n",
      "Epoch: 18, costo: 0.026506779715418816, accuracy 0.9759\n",
      "Epoch: 19, costo: 0.005035002715885639, accuracy 0.9775\n",
      "Epoch: 20, costo: 0.01319713145494461, accuracy 0.9773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(model1, optimizer, mb_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "e305a2e8-03a5-493b-a1e7-2d286ee77720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9769"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model1, x_test_tensor,  y_test_tensor, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "eefde0e9-5d71-4f65-963a-cfd8fdc0553e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0')"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "d8602ae6-8dc7-49fe-8ec5-684e28246de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 6\n",
      "Precition: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    rnd_idx = np.random.randint(len(y_train))\n",
    "    print(f'La imagen muestreada representa un: {y_train[rnd_idx][0]}')\n",
    "    predict = model1(input=x_train_tensor[rnd_idx,:].float().to(device=device)).argmax()\n",
    "    print(f'Precition: {predict}')\n",
    "    plot_number(x_train_num[rnd_idx])\n",
    "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    # print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961f702-4147-43f2-bd86-ec1583b4f958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
